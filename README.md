# LLMForChem

## Transformer

### Encoder and Decoder
编码器和解码器会将语言中的符号和发音转化为向量表示，提取并处理其中的语义关系，以便在生成输出时更好地理解和表达语言内容。

tokenizer 和 one-hot 编码为基础的语义单元（token）进行数字化。

- **Tokenizer**：将 token 投影到一维坐标轴上。
- **One-hot 编码**：为每个 token 分配一个单独的维度。

#### 两者的问题
- **独热编码**：
  - 空间维度过于高。
  - token 之间的语义关系完全靠维度之间的关系进行体现，无法充分利用空间中的长度关系。

- **分词器**：
  - 把所有的语义问题转换为了长度问题。
  - 完全没有利用维度关系去表示语义关系。

#### 中和方法
- 需要找一个==合适的空间==（潜空间）来完成编解码工作。

##### 理解潜空间

###### 什么是潜空间？
- **潜空间**：数据经过变换后所在的低维空间，通常维度低于原始数据空间。捕捉了数据的主要特征或模式。
- **潜在空间**：也称为隐空间（Latent Space）。

###### 为什么使用潜空间？
- **降维**：降低数据维度，使计算更高效，同时保留主要信息。
- **特征提取**：提取数据的主要特征，去除噪声和冗余信息。
- **可视化**：将高维数据投影到低维空间，便于理解数据结构。

###### 如何找到潜空间？
1. **基于分词后的 ID 进行维度提升**：
   - **Embedding**：将离散的词 ID 映射到连续的低维向量空间。
   - **例子**：NLP中的词嵌入（如 Word2Vec、GloVe）将词表示为低维向量。

2. **基于独热编码进行维度降低**：
   - **PCA（主成分分析）**：线性降维技术，将高维数据映射到低维潜空间。
   - **自编码器（Autoencoder）**：神经网络，通过压缩和解压缩学习数据的低维表示。

###### 例子
- **NLP中的词嵌入**：
  - **原始空间**：词的独热编码表示，维度等于词汇表大小。
  - **潜空间**：通过词嵌入，将词映射到低维向量表示。

- **图像处理中的自编码器**：
  - **原始空间**：图像像素值的高维空间。
  - **潜空间**：通过自编码器将图像压缩到低维潜空间，保留主要特征。

###### 总结
- **潜空间**是数据经过变换后的低维空间，捕捉了数据的主要特征。
- **实现方法**：嵌入、降维技术（如 PCA）或神经网络（如自编码器）。

潜空间用于更高效的数据处理和分析。

### Matrix and its transformation

#### 矩阵乘法没有交换律的理解

##### 1. 矩阵的类比
- **矩阵 \( A \)**：看作输入的数据（向量集合）。
- **矩阵 \( B \)**：看作一个函数（代表一系列操作）。
- **矩阵乘法 \( A \times B \)**：表示函数 \( B \) 作用于输入数据 \( A \)。

##### 2. 顺序的重要性
- **顺序解释**：
  - \( A \times B \)：对数据 \( A \) 应用操作 \( B \)。
  - \( B \times A \)：对操作 \( A \) 应用数据 \( B \)，这种顺序在实际操作中是无意义的。

##### 3. 函数复合的类比
- 假设有两个函数 \( f \) 和 \( g \)：
  - 先应用 \( g \) 再应用 \( f \) 得到 \( f(g(x)) \)。
  - 先应用 \( f \) 再应用 \( g \) 得到 \( g(f(x)) \)。
  - 由于函数复合不满足交换律，所以矩阵乘法也不满足交换律。

##### 4. 具体示例
- 给定矩阵 \( A \) 和 \( B \)：
  \[
  A = \begin{pmatrix} a & b \\ c & d \end{pmatrix}, \quad B = \begin{pmatrix} e & f \\ g & h \end{pmatrix}
  \]
- 计算：
  \[
  A \times B = \begin{pmatrix} ae+bg & af+bh \\ ce+dg & cf+dh \end{pmatrix}
  \]
  \[
  B \times A = \begin{pmatrix} ea+fc & eb+fd \\ ga+hc & gb+hd \end{pmatrix}
  \]
- 结果不同，说明 \( A \times B \neq B \times A \)。

##### 结论
- 矩阵乘法没有交换律，因为对数据应用操作与对操作应用数据的顺序不同，结果也不同。

### Space transformation
空间中的某个对象会按照一个或一组函数关系映射到另一个空间中。

若这一组函数关系都是线性变换的话，那就是线性变换。

矩阵的秩可以理解为要表示矩阵中所有向量所需的最小维度的空间。它表示了矩阵的行向量或列向量的线性无关性，反映了矩阵的“维度”。